{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Kernel Density Estimate Fitting on WNS 'Endemic Area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.291663Z",
     "start_time": "2017-12-12T22:59:34.813470Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import mapping, Polygon, MultiPolygon, LineString, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.883904Z",
     "start_time": "2017-12-12T22:59:37.762650Z"
    }
   },
   "outputs": [],
   "source": [
    "# wns_fname = os.path.join('data', \"WNS_Status_Provisional_8_30_2019.shp\")\n",
    "wns_fname = os.path.join('data', \"WNS_Status_Provisional_determination.shp\")\n",
    "\n",
    "wns = gpd.GeoDataFrame.from_file(wns_fname)\n",
    "wns['year'] = wns.map_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.915971Z",
     "start_time": "2017-12-12T22:59:37.890919Z"
    }
   },
   "outputs": [],
   "source": [
    "target_crs = {'proj': 'aea',\n",
    " 'lat_1': 29.5,\n",
    " 'lat_2': 45.5,\n",
    " 'lat_0': 23,\n",
    " 'lon_0': -96,\n",
    " 'x_0': 0,\n",
    " 'y_0': 0,\n",
    " 'datum': 'NAD83',\n",
    " 'units': 'm',\n",
    " 'no_defs': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.986118Z",
     "start_time": "2017-12-12T22:59:37.959062Z"
    }
   },
   "outputs": [],
   "source": [
    "states_fname = os.path.join('data', \"cb_2017_us_state_20m.shp\")\n",
    "states = gpd.read_file(states_fname)\n",
    "states_aea = states.to_crs(target_crs)\n",
    "conus_states = states_aea[~states_aea.NAME.isin(['Alaska', 'Hawaii', 'Puerto Rico'])]\n",
    "\n",
    "bounds = conus_states.bounds\n",
    "x_bounds = [bounds.minx.min(), bounds.maxx.max()]\n",
    "y_bounds = [bounds.miny.min(), bounds.maxy.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.023196Z",
     "start_time": "2017-12-12T22:59:37.996139Z"
    }
   },
   "outputs": [],
   "source": [
    "wns_centroid = wns.copy().to_crs({'init': 'epsg:4326'})\n",
    "wns_centroid.geometry = wns_centroid.geometry.centroid\n",
    "\n",
    "centroids = wns.centroid\n",
    "centroids = centroids.to_crs(target_crs)\n",
    "wns['x'] = centroids.x\n",
    "wns['y'] = centroids.y\n",
    "\n",
    "wns['area'] = centroids.to_crs(target_crs).geometry.area\n",
    "wns['area_weight'] = wns.area/wns.area.max()\n",
    "# wns.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.059272Z",
     "start_time": "2017-12-12T22:59:38.034219Z"
    }
   },
   "outputs": [],
   "source": [
    "def reclass_as_pcnt(Z):\n",
    "    uniques = np.unique(Z)[::-1]\n",
    "    z_reclass = np.copy(Z)\n",
    "    total_dens = Z.sum()\n",
    "    cum_area = 0.0\n",
    "    for u in uniques:\n",
    "        cum_area += np.count_nonzero(Z==u)*u\n",
    "        z_reclass[Z==u] = cum_area/total_dens\n",
    "    return z_reclass\n",
    "    #area_lookup[unique] = np.count_nonzero(z==unique)\n",
    "\n",
    "def create_kernel(x, y, X, Y, factor=1.2, weights=None):\n",
    "    \n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = gaussian_kde(values, weights=weights)#, bw_method='silverman')#, bw_method=0.15/np.asarray(values).std(ddof=1))\n",
    "#     kernel.silverman_factor()\n",
    "#     kernel.set_bandwidth(bw_method='silverman')\n",
    "    kernel.set_bandwidth( factor)\n",
    "    # kernel.set_bandwidth(bw_method=bw_method)\n",
    "    # kernel.set_bandwidth(bw_method=0.15/np.asarray(values).std(ddof=1))\n",
    "    Z = np.reshape(kernel(positions).T, X.shape)\n",
    "    return reclass_as_pcnt(Z)\n",
    "\n",
    "def create_kernel_contours(x, y, z, levels=[0.5, 0.75, 0.95]):\n",
    "    cset = plt.contour(x, y, z, levels=levels, colors=['red', 'white', 'blue'])\n",
    "    return cset\n",
    "\n",
    "\n",
    "\n",
    "def plot_one(x, y, X, Y, Z, title='', isopleth=0.75):\n",
    "    fig = plt.figure(figsize=(25, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    cset = create_kernel_contours(X, Y, Z, levels=[isopleth])   \n",
    "    \n",
    "#     ax.imshow(np.rot90(Z), cmap=plt.cm.Reds_r, \n",
    "#                extent=[X.min(), X.max(), Y.min(), Y.max()], alpha=0.6)\n",
    "\n",
    "    hull = Polygon(zip(x, y)).convex_hull\n",
    "    pnts = np.array(np.asarray(hull.exterior)).transpose()\n",
    "    \n",
    "#     ax.plot(pnts[0],pnts[1])\n",
    "    \n",
    "#     ax.plot(x, y, 'k.', markersize=6, alpha=0.4)\n",
    "#     ax.set_xlim([X.min(), X.max()])\n",
    "#     ax.set_ylim([Y.min(), Y.max()])\n",
    "    ax.set_xlim([-3000000, 3000000])\n",
    "    ax.set_ylim([0, 3700000])\n",
    "#     plt.colorbar()\n",
    "    states_aea.plot(color='None',  edgecolor='black', ax=ax, alpha=0.4)\n",
    "    plt.title(title,fontsize=30)\n",
    "#     plt.show()\n",
    "    ax.set_aspect('equal')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://gist.github.com/tillahoffmann/f844bce2ec264c1c8cb5\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class gaussian_kde(object):\n",
    "    \"\"\"Representation of a kernel-density estimate using Gaussian kernels.\n",
    "\n",
    "    Kernel density estimation is a way to estimate the probability density\n",
    "    function (PDF) of a random variable in a non-parametric way.\n",
    "    `gaussian_kde` works for both uni-variate and multi-variate data.   It\n",
    "    includes automatic bandwidth determination.  The estimation works best for\n",
    "    a unimodal distribution; bimodal or multi-modal distributions tend to be\n",
    "    oversmoothed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : array_like\n",
    "        Datapoints to estimate from. In case of univariate data this is a 1-D\n",
    "        array, otherwise a 2-D array with shape (# of dims, # of data).\n",
    "    bw_method : str, scalar or callable, optional\n",
    "        The method used to calculate the estimator bandwidth.  This can be\n",
    "        'scott', 'silverman', a scalar constant or a callable.  If a scalar,\n",
    "        this will be used directly as `kde.factor`.  If a callable, it should\n",
    "        take a `gaussian_kde` instance as only parameter and return a scalar.\n",
    "        If None (default), 'scott' is used.  See Notes for more details.\n",
    "    weights : array_like, shape (n, ), optional, default: None\n",
    "        An array of weights, of the same shape as `x`.  Each value in `x`\n",
    "        only contributes its associated weight towards the bin count\n",
    "        (instead of 1).\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dataset : ndarray\n",
    "        The dataset with which `gaussian_kde` was initialized.\n",
    "    d : int\n",
    "        Number of dimensions.\n",
    "    n : int\n",
    "        Number of datapoints.\n",
    "    neff : float\n",
    "        Effective sample size using Kish's approximation.\n",
    "    factor : float\n",
    "        The bandwidth factor, obtained from `kde.covariance_factor`, with which\n",
    "        the covariance matrix is multiplied.\n",
    "    covariance : ndarray\n",
    "        The covariance matrix of `dataset`, scaled by the calculated bandwidth\n",
    "        (`kde.factor`).\n",
    "    inv_cov : ndarray\n",
    "        The inverse of `covariance`.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    kde.evaluate(points) : ndarray\n",
    "        Evaluate the estimated pdf on a provided set of points.\n",
    "    kde(points) : ndarray\n",
    "        Same as kde.evaluate(points)\n",
    "    kde.pdf(points) : ndarray\n",
    "        Alias for ``kde.evaluate(points)``.\n",
    "    kde.set_bandwidth(bw_method='scott') : None\n",
    "        Computes the bandwidth, i.e. the coefficient that multiplies the data\n",
    "        covariance matrix to obtain the kernel covariance matrix.\n",
    "        .. versionadded:: 0.11.0\n",
    "    kde.covariance_factor : float\n",
    "        Computes the coefficient (`kde.factor`) that multiplies the data\n",
    "        covariance matrix to obtain the kernel covariance matrix.\n",
    "        The default is `scotts_factor`.  A subclass can overwrite this method\n",
    "        to provide a different method, or set it through a call to\n",
    "        `kde.set_bandwidth`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Bandwidth selection strongly influences the estimate obtained from the KDE\n",
    "    (much more so than the actual shape of the kernel).  Bandwidth selection\n",
    "    can be done by a \"rule of thumb\", by cross-validation, by \"plug-in\n",
    "    methods\" or by other means; see [3]_, [4]_ for reviews.  `gaussian_kde`\n",
    "    uses a rule of thumb, the default is Scott's Rule.\n",
    "\n",
    "    Scott's Rule [1]_, implemented as `scotts_factor`, is::\n",
    "\n",
    "        n**(-1./(d+4)),\n",
    "\n",
    "    with ``n`` the number of data points and ``d`` the number of dimensions.\n",
    "    Silverman's Rule [2]_, implemented as `silverman_factor`, is::\n",
    "\n",
    "        (n * (d + 2) / 4.)**(-1. / (d + 4)).\n",
    "\n",
    "    Good general descriptions of kernel density estimation can be found in [1]_\n",
    "    and [2]_, the mathematics for this multi-dimensional implementation can be\n",
    "    found in [1]_.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] D.W. Scott, \"Multivariate Density Estimation: Theory, Practice, and\n",
    "           Visualization\", John Wiley & Sons, New York, Chicester, 1992.\n",
    "    .. [2] B.W. Silverman, \"Density Estimation for Statistics and Data\n",
    "           Analysis\", Vol. 26, Monographs on Statistics and Applied Probability,\n",
    "           Chapman and Hall, London, 1986.\n",
    "    .. [3] B.A. Turlach, \"Bandwidth Selection in Kernel Density Estimation: A\n",
    "           Review\", CORE and Institut de Statistique, Vol. 19, pp. 1-33, 1993.\n",
    "    .. [4] D.M. Bashtannyk and R.J. Hyndman, \"Bandwidth selection for kernel\n",
    "           conditional density estimation\", Computational Statistics & Data\n",
    "           Analysis, Vol. 36, pp. 279-298, 2001.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Generate some random two-dimensional data:\n",
    "\n",
    "    >>> from scipy import stats\n",
    "    >>> def measure(n):\n",
    "    >>>     \"Measurement model, return two coupled measurements.\"\n",
    "    >>>     m1 = np.random.normal(size=n)\n",
    "    >>>     m2 = np.random.normal(scale=0.5, size=n)\n",
    "    >>>     return m1+m2, m1-m2\n",
    "\n",
    "    >>> m1, m2 = measure(2000)\n",
    "    >>> xmin = m1.min()\n",
    "    >>> xmax = m1.max()\n",
    "    >>> ymin = m2.min()\n",
    "    >>> ymax = m2.max()\n",
    "\n",
    "    Perform a kernel density estimate on the data:\n",
    "\n",
    "    >>> X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    >>> positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    >>> values = np.vstack([m1, m2])\n",
    "    >>> kernel = stats.gaussian_kde(values)\n",
    "    >>> Z = np.reshape(kernel(positions).T, X.shape)\n",
    "\n",
    "    Plot the results:\n",
    "\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> fig = plt.figure()\n",
    "    >>> ax = fig.add_subplot(111)\n",
    "    >>> ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "    ...           extent=[xmin, xmax, ymin, ymax])\n",
    "    >>> ax.plot(m1, m2, 'k.', markersize=2)\n",
    "    >>> ax.set_xlim([xmin, xmax])\n",
    "    >>> ax.set_ylim([ymin, ymax])\n",
    "    >>> plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, bw_method=None, weights=None):\n",
    "        self.dataset = np.atleast_2d(dataset)\n",
    "        if not self.dataset.size > 1:\n",
    "            raise ValueError(\"`dataset` input should have multiple elements.\")\n",
    "        self.d, self.n = self.dataset.shape\n",
    "            \n",
    "        if weights is not None:\n",
    "            self.weights = weights / np.sum(weights)\n",
    "        else:\n",
    "            self.weights = np.ones(self.n) / self.n\n",
    "            \n",
    "        # Compute the effective sample size \n",
    "        # http://surveyanalysis.org/wiki/Design_Effects_and_Effective_Sample_Size#Kish.27s_approximate_formula_for_computing_effective_sample_size\n",
    "        self.neff = 1.0 / np.sum(self.weights ** 2)\n",
    "\n",
    "        self.set_bandwidth(bw_method=bw_method)\n",
    "\n",
    "    def evaluate(self, points):\n",
    "        \"\"\"Evaluate the estimated pdf on a set of points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        points : (# of dimensions, # of points)-array\n",
    "            Alternatively, a (# of dimensions,) vector can be passed in and\n",
    "            treated as a single point.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        values : (# of points,)-array\n",
    "            The values at each point.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError : if the dimensionality of the input points is different than\n",
    "                     the dimensionality of the KDE.\n",
    "\n",
    "        \"\"\"\n",
    "        points = np.atleast_2d(points)\n",
    "\n",
    "        d, m = points.shape\n",
    "        if d != self.d:\n",
    "            if d == 1 and m == self.d:\n",
    "                # points was passed in as a row vector\n",
    "                points = np.reshape(points, (self.d, 1))\n",
    "                m = 1\n",
    "            else:\n",
    "                msg = \"points have dimension %s, dataset has dimension %s\" % (d,\n",
    "                    self.d)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "        # compute the normalised residuals\n",
    "        chi2 = cdist(points.T, self.dataset.T, 'mahalanobis', VI=self.inv_cov) ** 2\n",
    "        # compute the pdf\n",
    "        result = np.sum(np.exp(-.5 * chi2) * self.weights, axis=1) / self._norm_factor\n",
    "\n",
    "        return result\n",
    "\n",
    "    __call__ = evaluate\n",
    "\n",
    "    def scotts_factor(self):\n",
    "        return np.power(self.neff, -1./(self.d+4))\n",
    "\n",
    "    def silverman_factor(self):\n",
    "        return np.power(self.neff*(self.d+2.0)/4.0, -1./(self.d+4))\n",
    "\n",
    "    #  Default method to calculate bandwidth, can be overwritten by subclass\n",
    "    covariance_factor = scotts_factor\n",
    "\n",
    "    def set_bandwidth(self, bw_method=None):\n",
    "        \"\"\"Compute the estimator bandwidth with given method.\n",
    "\n",
    "        The new bandwidth calculated after a call to `set_bandwidth` is used\n",
    "        for subsequent evaluations of the estimated density.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bw_method : str, scalar or callable, optional\n",
    "            The method used to calculate the estimator bandwidth.  This can be\n",
    "            'scott', 'silverman', a scalar constant or a callable.  If a\n",
    "            scalar, this will be used directly as `kde.factor`.  If a callable,\n",
    "            it should take a `gaussian_kde` instance as only parameter and\n",
    "            return a scalar.  If None (default), nothing happens; the current\n",
    "            `kde.covariance_factor` method is kept.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        .. versionadded:: 0.11\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> x1 = np.array([-7, -5, 1, 4, 5.])\n",
    "        >>> kde = stats.gaussian_kde(x1)\n",
    "        >>> xs = np.linspace(-10, 10, num=50)\n",
    "        >>> y1 = kde(xs)\n",
    "        >>> kde.set_bandwidth(bw_method='silverman')\n",
    "        >>> y2 = kde(xs)\n",
    "        >>> kde.set_bandwidth(bw_method=kde.factor / 3.)\n",
    "        >>> y3 = kde(xs)\n",
    "\n",
    "        >>> fig = plt.figure()\n",
    "        >>> ax = fig.add_subplot(111)\n",
    "        >>> ax.plot(x1, np.ones(x1.shape) / (4. * x1.size), 'bo',\n",
    "        ...         label='Data points (rescaled)')\n",
    "        >>> ax.plot(xs, y1, label='Scott (default)')\n",
    "        >>> ax.plot(xs, y2, label='Silverman')\n",
    "        >>> ax.plot(xs, y3, label='Const (1/3 * Silverman)')\n",
    "        >>> ax.legend()\n",
    "        >>> plt.show()\n",
    "\n",
    "        \"\"\"\n",
    "        if bw_method is None:\n",
    "            pass\n",
    "        elif bw_method == 'scott':\n",
    "            self.covariance_factor = self.scotts_factor\n",
    "        elif bw_method == 'silverman':\n",
    "            self.covariance_factor = self.silverman_factor\n",
    "        elif np.isscalar(bw_method):\n",
    "            self._bw_method = 'use constant'\n",
    "            self.covariance_factor = lambda: self.factor / bw_method\n",
    "        elif callable(bw_method):\n",
    "            self._bw_method = bw_method\n",
    "            self.covariance_factor = lambda: self._bw_method(self)\n",
    "        else:\n",
    "            msg = \"`bw_method` should be 'scott', 'silverman', a scalar \" \\\n",
    "                  \"or a callable.\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self._compute_covariance()\n",
    "\n",
    "    def _compute_covariance(self):\n",
    "        \"\"\"Computes the covariance matrix for each Gaussian kernel using\n",
    "        covariance_factor().\n",
    "        \"\"\"\n",
    "        self.factor = self.covariance_factor()\n",
    "        # Cache covariance and inverse covariance of the data\n",
    "        if not hasattr(self, '_data_inv_cov'):\n",
    "            # Compute the mean and residuals\n",
    "            _mean = np.sum(self.weights * self.dataset, axis=1)\n",
    "            _residual = (self.dataset - _mean[:, None])\n",
    "            # Compute the biased covariance\n",
    "            self._data_covariance = np.atleast_2d(np.dot(_residual * self.weights, _residual.T))\n",
    "            # Correct for bias (http://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Weighted_sample_covariance)\n",
    "            self._data_covariance /= (1 - np.sum(self.weights ** 2))\n",
    "            self._data_inv_cov = np.linalg.inv(self._data_covariance)\n",
    "\n",
    "        self.covariance = self._data_covariance * self.factor**2\n",
    "        self.inv_cov = self._data_inv_cov / self.factor**2\n",
    "        self._norm_factor = np.sqrt(np.linalg.det(2*np.pi*self.covariance)) #* self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:37.951045Z",
     "start_time": "2017-12-12T22:59:37.925992Z"
    }
   },
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def interactive_plot(factor, iso=0.75, year=2017, \n",
    "                     add_counties=False, \n",
    "                     add_centroids=True,\n",
    "                     add_surface=True,\n",
    "                     weight_by_county_area=True,\n",
    "                     weight_by_year=True):\n",
    "    if year in cache:\n",
    "        X, Y, data = cache[year]['data']\n",
    "    else:\n",
    "        cache[year] = {}\n",
    "        cache[year]['kernels'] = {}\n",
    "        data = wns[wns.year <= year]\n",
    "        data.years_pres = data.year.max()-data.year\n",
    "        data = data[~data.determinat.isin(['Pd negative', 'WNS negative'])]\n",
    "        \n",
    "        pad=500000\n",
    "        X, Y = np.mgrid[x_bounds[0]-pad:x_bounds[1]+pad:100j, y_bounds[0]-pad:y_bounds[1]+pad:100j]\n",
    "        cache[year]['data'] = (X, Y, data)\n",
    "    \n",
    "    \n",
    "    if weight_by_year:\n",
    "        year_weights = gen_year_weights()\n",
    "        weights = data.years_pres.apply(lambda x: year_weights[x])\n",
    "    else:\n",
    "        weights = np.ones(data.area_weight.shape)\n",
    "        \n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    if weight_by_county_area:\n",
    "        county_weights = data.area_weight\n",
    "        county_weights /= np.sum(county_weights)\n",
    "        weights *= county_weights\n",
    "        \n",
    "#     weights /= np.sum(weights)\n",
    "    weights = list(weights)\n",
    "\n",
    "    Z = create_kernel(data.x, data.y, X, Y, factor, weights=weights)\n",
    "    cache[year]['kernels'][factor] = Z\n",
    "        \n",
    "        \n",
    "    ax = plot_one(data.x, data.y, X, Y, Z, isopleth=iso, title=f\"WNS {year}-{year+1}\")\n",
    "    \n",
    "    if add_surface:\n",
    "        ax.imshow(np.rot90(Z), cmap=plt.cm.Reds_r, \n",
    "           extent=[X.min(), X.max(), Y.min(), Y.max()], alpha=0.6)\n",
    "    \n",
    "    if add_counties:\n",
    "        data.to_crs(states_aea.crs).plot(column='year', cmap='plasma', ax=ax, legend=True)\n",
    "\n",
    "    if add_centroids:\n",
    "        data.to_crs(states_aea.crs).centroid.plot(color='grey', ax=ax)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T22:59:38.187540Z",
     "start_time": "2017-12-12T22:59:38.110379Z"
    }
   },
   "outputs": [],
   "source": [
    "bw_w = widgets.FloatSlider(\n",
    "    value=1.2,\n",
    "    min=0.1,\n",
    "    max=4.0,\n",
    "    step=0.1,\n",
    "    description=\"BW Factor\")\n",
    "\n",
    "bw_w.continuous_update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_w = widgets.IntSlider(\n",
    "    value=2014,\n",
    "    min=wns.year.min()+1,\n",
    "    max=wns.year.max(),\n",
    "    step=1,\n",
    "    description=\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_w = widgets.FloatSlider(\n",
    "    value=0.75,\n",
    "    min=0.05,\n",
    "    max=.99,\n",
    "    step=0.05,\n",
    "    description=\"Isopleth\")\n",
    "\n",
    "iso_w.continuous_update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_counties = widgets.Checkbox(value=False, description='Show Counties')\n",
    "show_centroids = widgets.Checkbox(value=False, description='Show Centroids')\n",
    "show_kde = widgets.Checkbox(value=False, description='Show KDE Surface')\n",
    "weight_by_county = widgets.Checkbox(value=True, description='Weight by county areas')\n",
    "weight_by_year = widgets.Checkbox(value=True, description='Weight by years since detection')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to weight counties we need to decide on a function to use for weighting.\n",
    "#### Let's start with a simple number of years raised to a power function, as it allows us to explore a range of curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*move the slider below to set the shape of this curve*\n",
    "* 0.0 is no weight\n",
    "* 1.0 is linear\n",
    "\n",
    "***Note: Changes to this curve do not update the map until one of the widgets below is triggered***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d93d38586ad4ba5ad05e991f8f047a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='Weight Exponent', layout=La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_f = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=0.0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description=\"Weight Exponent\",\n",
    "    layout={'width': '500px'},\n",
    "    style={'description_width': 'initial'},\n",
    "    continuous_update=False)\n",
    "\n",
    "skip_last_years = widgets.IntSlider(\n",
    "    value=4,\n",
    "    min=0.0,\n",
    "    max=10.0,\n",
    "    description=\"Number of years to skip\",\n",
    "    layout={'width': '500px'},\n",
    "    style={'description_width': 'initial'})\n",
    "\n",
    "def exponential(x, factor=0.0):\n",
    "    return x**factor\n",
    "\n",
    "wns['years_pres'] = wns.year.max()-wns.year\n",
    "\n",
    "def gen_year_weights():\n",
    "    years = list(range(0, wns.years_pres.max() + 1))\n",
    "    \n",
    "    max_val = (years[-1]-skip_last_years.value)**weight_f.value\n",
    "    \n",
    "    weight_lookup = {}\n",
    "    for year in years:\n",
    "        if year < skip_last_years.value:\n",
    "            weight_lookup[year] = 0\n",
    "        elif year >= skip_last_years.value:\n",
    "            weight_lookup[year] = ((year-skip_last_years.value)**weight_f.value)/max_val\n",
    "       \n",
    "    return weight_lookup\n",
    "\n",
    "def show_weight_curve(factor=0, skip_years=4):\n",
    "   \n",
    "    weights_lookup = gen_year_weights()\n",
    "    \n",
    "    f, ax1 = plt.subplots(1, 1, figsize=(6,4))\n",
    "    \n",
    "    ax1.scatter(weights_lookup.keys(), weights_lookup.values(), color='r', linewidth=10)\n",
    "    ax1.set_title('County Weights by Years since detection')\n",
    "    ax1.set_xlabel('Years since Detection (n)')\n",
    "    ax1.set_ylabel('Weight')\n",
    "    \n",
    "    ax1.set_ylim(-0.05, 1.1)\n",
    "    \n",
    "#     tex = r'($n-' +str(skip_years) + r')^{' + str(factor) + '}$'\n",
    "#     ax1.text(1, 0.8, tex, fontsize=20, va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "_ = interact(show_weight_curve, factor=weight_f, skip_years=skip_last_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once the weight function is finished used the sliders below to see the effect on our KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7404f40f6b38460489e568e0b47afacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.2, continuous_update=False, description='BW Factor', max=4.0, min=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "_ = interact(interactive_plot, factor=bw_w, iso=iso_w, year=year_w, \n",
    "             add_counties=show_counties,\n",
    "             add_centroids=show_centroids,\n",
    "             add_surface=show_kde,\n",
    "             weight_by_county_area=weight_by_county,\n",
    "             weight_by_years=weight_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import polygon\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "from shapely import geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Shapefiles\n",
    "def save_kdes():\n",
    "    rows = []\n",
    "    for year in sorted(wns.year.unique())[1:]:\n",
    "#         print(year)\n",
    "\n",
    "        data = wns[wns.year <= year]\n",
    "        data = data[~data.determinat.isin(['Pd negative', 'WNS negative'])]\n",
    "    \n",
    "        pad=500000\n",
    "        X, Y = np.mgrid[x_bounds[0]-pad:x_bounds[1]+pad:100j, y_bounds[0]-pad:y_bounds[1]+pad:100j]\n",
    "\n",
    "        if weight_by_county.value:\n",
    "            year_weights = gen_year_weights()\n",
    "            weights = data.years_pres.apply(lambda x: year_weights[x])\n",
    "        else:\n",
    "            weights = np.ones(data.area_weight.shape)\n",
    "\n",
    "        weights /= np.sum(weights)\n",
    "\n",
    "        if weight_by_county.value:\n",
    "            county_weights = data.area_weight\n",
    "            county_weights /= np.sum(county_weights)\n",
    "            weights *= county_weights\n",
    "\n",
    "        #     weights /= np.sum(weights)\n",
    "        weights = list(weights)\n",
    "\n",
    "        Z = create_kernel(data.x, data.y, X, Y, factor=bw_w.value, weights=weights)\n",
    "        cset = create_kernel_contours(X, Y, Z, levels=[iso_w.value])\n",
    "\n",
    "        p = cset.collections[0].get_paths()[0]\n",
    "        v = p.vertices\n",
    "        x = v[:,0]\n",
    "        y = v[:,1]\n",
    "\n",
    "\n",
    "        polys = []\n",
    "        for col in cset.collections:\n",
    "    #         print('col')\n",
    "            # Loop through all polygons that have the same intensity level\n",
    "            for contour_path in col.get_paths():\n",
    "    #             print('c_path')\n",
    "                # Create the polygon for this intensity level\n",
    "                # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "                for ncp, cp in enumerate(contour_path.to_polygons()):\n",
    "                    x = np.array(cp)[:,0]\n",
    "                    y = np.array(cp)[:,1]\n",
    "                    new_shape = geometry.Polygon([(i[0], i[1]) for i in zip(x,y)])\n",
    "\n",
    "                    hole = False\n",
    "                    for p in polys:\n",
    "                        if p.contains(new_shape):\n",
    "                            p = polys.pop(polys.index(p))\n",
    "                            hole = True\n",
    "                            new_shape = p.difference(new_shape)\n",
    "\n",
    "                    polys.append(new_shape)\n",
    "\n",
    "        mp = MultiPolygon(polys)             \n",
    "\n",
    "\n",
    "        row ={'year':year,\n",
    "              'iso':iso_w.value,\n",
    "              'bw_factor':bw_w.value,\n",
    "              'skip_years':skip_last_years.value,\n",
    "              'weight_exp':weight_f.value,\n",
    "              'geometry':mp}\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    gdf = geopandas.GeoDataFrame(\n",
    "        df, geometry=df.geometry)\n",
    "    gdf.crs = target_crs\n",
    "\n",
    "    gdf.to_file(r\"data\\wns_endemic.shp\")\n",
    "    plt.close()\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prettier leaflet map of these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_style(feature):\n",
    "    \n",
    "    y = feature['properties']['map_year']\n",
    "    determination = feature['properties']['determinat']\n",
    "#     print(y, suspect)\n",
    "    \n",
    "    if this_year-y >= skip_last_years.value:\n",
    "        fillcolor = year_colors[-1]\n",
    "        linewidth = .5\n",
    "        opacity = 0.2\n",
    "        fill_opacity = 0.4\n",
    "    else:\n",
    "        fillcolor = year_colors[this_year-y]\n",
    "        linewidth = .5\n",
    "        opacity = 0.9\n",
    "        fill_opacity = 0.7\n",
    "        \n",
    "    wns_outline_color = 'grey'\n",
    "    pd_outline_color = 'grey'       \n",
    "        \n",
    "    if determination == 'WNS positive':\n",
    "        return {'fillColor':fillcolor,\n",
    "               'weight':linewidth,\n",
    "               'color':wns_outline_color,\n",
    "               'opacity':opacity,\n",
    "               'fillOpacity':fill_opacity}\n",
    "    if determination == 'WNS suspect':\n",
    "        return {'fillColor':fillcolor,\n",
    "#                 'fillPattern':suspect, \n",
    "               'weight':linewidth,\n",
    "               'color':wns_outline_color,\n",
    "               'opacity':opacity,\n",
    "               'fillOpacity':fill_opacity}\n",
    "    if determination == 'WNS negative':\n",
    "        return {'fillColor':fillcolor,\n",
    "#                 'fillPattern':suspect, \n",
    "               'weight':linewidth+2,\n",
    "               'color':wns_outline_color,\n",
    "               'opacity':opacity,\n",
    "               'fillOpacity':fill_opacity}\n",
    "    if determination == 'Pd positive':\n",
    "        return {'fillColor':fillcolor,\n",
    "               'weight':linewidth,\n",
    "               'color':pd_outline_color,\n",
    "               'opacity':opacity,\n",
    "               'fillOpacity':fill_opacity}\n",
    "    if determination == 'Pd presumed':\n",
    "        return {'fillColor':fillcolor,\n",
    "#                 'fillPattern':suspect, \n",
    "               'weight':linewidth,\n",
    "               'color':pd_outline_color,\n",
    "               'opacity':opacity,\n",
    "               'fillOpacity':fill_opacity}\n",
    "    if determination == 'Pd negative':\n",
    "        return {'fillColor':fillcolor,\n",
    "               'weight':linewidth+2,\n",
    "               'color':wns_outline_color,\n",
    "               'opacity':opacity,\n",
    "               'fillOpacity':fill_opacity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_map():\n",
    "    m = folium.Map([39, -85], zoom_start=5, tiles='cartodbpositron', control_scale=True)\n",
    "    # for p in year_suspect:\n",
    "    #     p.add_to(m)\n",
    "    # endemic_suspect.add_to(m)\n",
    "    global this_year\n",
    "    this_year = year_dropdown.value\n",
    "\n",
    "    wns_subset = wns[wns.map_year <= this_year]\n",
    "\n",
    "    highlight_style = lambda feature: {'color':'black',\n",
    "                                          'weight':3, 'opacity':0.7}\n",
    "\n",
    "    gj = folium.GeoJson(kdes[kdes.year==this_year-skip_last_years.value], \n",
    "                        name=f\"Endemic Area: <= {this_year-skip_last_years.value}\",\n",
    "                       style_function=lambda feature: {'fillColor':endemic_color.value, \n",
    "                                                       'weight':0.5,\n",
    "                                                       'color':'grey',\n",
    "                                                       'opacity':0.5,\n",
    "                                                       'fillOpacity':0.75}).add_to(m)\n",
    "\n",
    "    #Add endemic counties to Map\n",
    "    endemic_counties = wns_subset#[((wns2.year <= this_year-n_years))]\n",
    "    endemic_tool_tip_geojson = folium.features.GeoJsonTooltip(\n",
    "            fields=['map_year', 'determinat', 'countyname', 'stateprov'],\n",
    "            aliases=[\"year\", \"White Nose STATUS\", \"County\", \"State/Province\"],\n",
    "            labels=True,\n",
    "            localize=False,\n",
    "            style=None,\n",
    "        )\n",
    "    folium.GeoJson(endemic_counties, name=f\"Endemic Area Counties\",\n",
    "                           tooltip=endemic_tool_tip_geojson,\n",
    "                           style_function=get_county_style,\n",
    "                           highlight_function=highlight_style).add_to(m)\n",
    "\n",
    "    sus_alpha = 0.3\n",
    "\n",
    "    wns_centroid_subset = wns_centroid[wns_centroid.map_year <= this_year]\n",
    "    for row in wns_centroid_subset.iterrows():\n",
    "        determination = row[1]['determinat']\n",
    "        geom = row[1]['geometry']\n",
    "\n",
    "        if 'WNS' in determination:\n",
    "            line_color = wns_color.value\n",
    "        else:\n",
    "            line_color=pd_color.value\n",
    "\n",
    "        if 'positive' in determination:\n",
    "            fillOpacity = 1.0\n",
    "        elif 'negative' in determination:\n",
    "            fillOpacity = 0.0\n",
    "        else:\n",
    "            fillOpacity = sus_alpha\n",
    "\n",
    "    #     print(determination, geom)\n",
    "        folium.Circle(\n",
    "        location=[geom.y, geom.x],\n",
    "        radius=10000,\n",
    "        color=line_color,\n",
    "        fill=True,\n",
    "        fill_color=line_color,\n",
    "        fill_opacity = fillOpacity,\n",
    "        weight=0.5).add_to(m)\n",
    "\n",
    "\n",
    "    schoharie = wns[wns.countyname == 'Schoharie'].to_crs({'init': 'epsg:4326'})\n",
    "    schoharie.geometry = schoharie.geometry.centroid\n",
    "    folium.Circle(\n",
    "        location=[schoharie.geometry.y, schoharie.geometry.x],\n",
    "        radius=50000,\n",
    "        color=line_color,\n",
    "        tooltip='First detected February 2006\\nSchoharie Co. NY',\n",
    "        fill=False,\n",
    "        weight=2.0).add_to(m)\n",
    "\n",
    "    title_html = f\"\"\"<div class='my-Title' style='position: absolute; \n",
    "    z-index:9999; \n",
    "    font-size:38px;  \n",
    "    padding: 20px;\n",
    "    width: 100%;\n",
    "    color: white;\n",
    "    background-color: #343a40;\n",
    "    text-align:center;'>\n",
    "\n",
    "    <b>White-Nose Syndrome Spread Map {this_year}-{this_year+1}</b> \n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "    legend_html = f\"\"\"<div class='my-legend' style='position: fixed; z-index:9999; font-size:14px;  \n",
    "        bottom: 20px; right: 10px; padding: 10px;\n",
    "         border:2px solid grey; background-color:rgba(255, 255, 255, 0.7);\n",
    "         border-radius:6px'>\n",
    "    <div class='legend-title'>Legend</div>\n",
    "    <div class='legend-scale'>\n",
    "      <ul class='legend-labels'>\"\"\"\n",
    "\n",
    "    for y in range(skip_last_years.value):\n",
    "        legend_html += f\"\\n<li><span style='background:{year_colors[y]};opacity:0.7;'></span>{this_year-y-1}-{this_year-y}</li>\"\n",
    "\n",
    "    legend_html += f\"\"\"\n",
    "        <li><span style='background:{year_colors[-1]};opacity:0.7;'></span>Counties <= {this_year-4}</li>\n",
    "        <li><span style='background:{endemic_color.value};opacity:0.7;'></span>Endemic Area</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <p class='legend-source'>WNS Positive\n",
    "    <span class=\"dot\" style='background-color:{wns_color.value};border-color:{wns_color.value};float: right;'></span>\n",
    "    </p>\n",
    "    <p class='legend-source'>WNS Suspect \n",
    "     <span class=\"dot\" style='background-color:{wns_color.value};border-color:{wns_color.value};opacity:{sus_alpha};position: relative; top: 0px; left: 0px;float: right;'></span>\n",
    "     <span class=\"dot\" style='background-color:transparent;border-color:{wns_color.value};opacity:1.0;position: relative; top: 0px; left: 13px;float: right;'></span>\n",
    "    </p>\n",
    "    <p class='legend-source'>WNS Negative\n",
    "     <span class=\"dot\" style='background-color:transparent;border-color:{wns_color.value};opacity:1.0;float: right;'></span>\n",
    "    </p>\n",
    "\n",
    "    <p class='legend-source'>Pd Positive\n",
    "    <span class=\"dot\" style='background-color:{pd_color.value};border-color:{pd_color.value};float: right;'></span>\n",
    "    </p>\n",
    "    <p class='legend-source'>Pd Presumed\n",
    "     <span class=\"dot\" style='background-color:{pd_color.value};border-color:{pd_color.value};opacity:{sus_alpha};position: relative; top: 0px; left: 0px;float: right;'></span>\n",
    "     <span class=\"dot\" style='background-color:transparent;border-color:{pd_color.value};opacity:1.0;position: relative; top: 0px; left: 13px;float: right;'></span>\n",
    "    </p>\n",
    "    <p class='legend-source'>Pd Negative\n",
    "     <span class=\"dot\" style='background-color:transparent;border-color:{pd_color.value};opacity:1.0;float: right;'></span>\n",
    "    </p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    legend_html += \"\"\"\n",
    "    <style type='text/css'>\n",
    "      .my-legend .legend-title {\n",
    "        text-align: left;\n",
    "        margin-bottom: 5px;\n",
    "        font-weight: bold;\n",
    "        font-size: 90%;\n",
    "        }\n",
    "      .my-legend .legend-scale ul {\n",
    "        margin: 0;\n",
    "        margin-bottom: 5px;\n",
    "        padding: 0;\n",
    "        float: left;\n",
    "        list-style: none;\n",
    "        }\n",
    "      .my-legend .legend-scale ul li {\n",
    "        font-size: 80%;\n",
    "        list-style: none;\n",
    "        margin-left: 0;\n",
    "        line-height: 18px;\n",
    "        margin-bottom: 2px;\n",
    "        }\n",
    "      .my-legend ul.legend-labels li span {\n",
    "        display: block;\n",
    "        float: left;\n",
    "        height: 16px;\n",
    "        width: 30px;\n",
    "        margin-right: 5px;\n",
    "        margin-left: 0;\n",
    "        border: 1px solid #999;\n",
    "        }\n",
    "      .my-legend .legend-source {\n",
    "        font-size: 80%;\n",
    "        color: #777;\n",
    "        clear: both;\n",
    "        }\n",
    "      .my-legend a {\n",
    "        color: #777;\n",
    "        }\n",
    "      .dot {\n",
    "            height: 12px;\n",
    "            width: 12px;\n",
    "            border-radius: 50%;\n",
    "            border-width: 2px;\n",
    "            border-style: solid;\n",
    "            display: inline-block;\n",
    "            } \n",
    "\n",
    "        }\n",
    "    </style>\"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "\n",
    "    img_html = \"\"\"\n",
    "    <img src=\"https://sciencebase.usgs.gov/nabat/assets/NABat_long_2line_color_white.png\" alt=\"NABat Logo\" style=\"position: fixed; \n",
    "    z-index:9999; \n",
    "    top: 3px;\n",
    "    left: 3px;\n",
    "    padding: 10px;\n",
    "\n",
    "    height: 55px;\n",
    "    \">\"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(img_html))\n",
    "\n",
    "    plugins.Fullscreen(\n",
    "        position='bottomleft',\n",
    "        title='Expand me',\n",
    "        title_cancel='Exit me',\n",
    "        force_separate_button=True\n",
    "    ).add_to(m)\n",
    "\n",
    "    minimap = plugins.MiniMap(toggle_display=True, position='bottomleft')\n",
    "    minimap.add_to(m)\n",
    "\n",
    "#     m.save('wns.html')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47b0ab83c3a4886b67f27042bb594a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ColorMap:', index=1, options=('Accent', 'Blues', 'BrBG', 'BuGn', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormaps = [c for c in dir(mpl.cm) if '_' not in c]\n",
    "colormaps.sort()\n",
    "for cruft in ['LUTSIZE', 'ScalarMappable', 'colors', 'functools']:\n",
    "    try:\n",
    "        colormaps.pop(colormaps.index(cruft))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "cm_dropdown = widgets.Dropdown(\n",
    "    options=colormaps,\n",
    "    value=colormaps[1],\n",
    "    description='ColorMap:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "reverse = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Reverse Ramp',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def change_cm(cm, r=False):\n",
    "    global color_map\n",
    "    color_map = mpl.cm.get_cmap(cm)\n",
    "    global year_colors\n",
    "    year_colors = [mpl.colors.to_hex(color_map(c)) for c in np.linspace(0, 1, skip_last_years.value+1)]\n",
    "    \n",
    "    if reverse.value:\n",
    "        year_colors.reverse()\n",
    "    \n",
    "    sns.palplot(year_colors)\n",
    "    \n",
    "_ = interact(change_cm, cm=cm_dropdown, r=reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8840af9e765e4af9ad9ad5f2c0f9a9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(ColorPicker(value='red', description='Pick a color for WNS indicators', style=DescriptionStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wns_color = widgets.ColorPicker(\n",
    "    concise=False,\n",
    "    description='Pick a color for WNS indicators',\n",
    "    value='red',\n",
    "    disabled=False,\n",
    "    style={'description_width':'initial'}\n",
    ")\n",
    "\n",
    "pd_color = widgets.ColorPicker(\n",
    "    concise=False,\n",
    "    description='Pick a color for Pd indicators',\n",
    "    value='orange',\n",
    "    disabled=False,\n",
    "    style={'description_width':'initial'}\n",
    ")\n",
    "\n",
    "endemic_color = widgets.ColorPicker(\n",
    "    concise=False,\n",
    "    description='Pick a color for endemic area',\n",
    "    value=\"#b3cd9f\",\n",
    "    disabled=False,\n",
    "    style={'description_width':'initial'}\n",
    ")\n",
    "widgets.HBox([wns_color, pd_color, endemic_color])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec36bf6e32e24035bbf449cb47aaabcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Year of map:', index=12, options=(2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year_dropdown = widgets.Dropdown(\n",
    "    options=[y for y in wns.map_year.unique()],\n",
    "    value=wns.map_year.unique()[-1],\n",
    "    description='Year of map:',\n",
    "    disabled=False,\n",
    ")\n",
    "year_dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a055f40963c1479a90ebfc0f53f80719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Update Map', style=ButtonStyle(), tooltip='Update Map')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec2fdbc9e6a4bd3ab7f20eb3fb89fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_button = widgets.Button(\n",
    "    description='Update Map',\n",
    "    disabled=False,\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Update Map',\n",
    ")\n",
    "output = widgets.Output()\n",
    "display(update_button, output)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        global kdes\n",
    "        kdes = save_kdes()\n",
    "        \n",
    "        global m\n",
    "        m = make_map()\n",
    "        clear_output()\n",
    "        display(m)\n",
    "\n",
    "update_button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
